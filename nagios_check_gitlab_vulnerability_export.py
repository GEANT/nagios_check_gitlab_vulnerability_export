#!/usr/bin/env python3
import argparse
import sys
from pprint import pprint
from pathlib import Path
from pathlib import PurePath
import os.path
import csv
import json

# pip install requests
import requests

# https://www.peterbe.com/plog/best-practice-with-retries-with-requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

def requests_retry_session(
    retries=3,
    backoff_factor=0.3,
    status_forcelist=(500, 502, 504, 404),
    session=None,
):
    session = session or requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

def nagios_exit(message, code):
    print(message)
    sys.exit(code)


# Debug
# import logging
# logging.basicConfig(level=logging.DEBUG)


try:
    parser = argparse.ArgumentParser(description='Monitor the vulnerabilities in Gitlab generated reports')
    parser.add_argument('--api',
            help='''
            The API URL to use. See https://docs.gitlab.com/ee/api/vulnerability_exports.html
            for examples. This can use project, group, or instance level reports.
            Example: "https://gitlab.my.org/api/v4/groups/234/vulnerability_exports"
            ''',
            required=True)
    parser.add_argument('--token',
            help='Access token to use for authentication',
            required=True)
    parser.add_argument('--diff',
            help='''
            Instead of the absolute number of vulnerabilties in the report, use the difference compared to
            the previous report. This effectively means you just see the changes.
            A temporary file will be used to store the relevant report details for comparison between
            checks. See also the '--cachedir' option.
            ''',
            action="store_true")
    parser.add_argument('--warn', '-w',
            help='Number of found vulnerabilities that should result in a WARNING (default: 1))',
            required=False,
            type=int,
            default=1)
    parser.add_argument('--crit', '-c',
            help='Number of found vulnerabilities that should result in a CRITICAL (default: 3))',
            required=False,
            type=int,
            default=3)
    parser.add_argument('--severity',
            help='''
            Comma separated list of vulnerability severities to take into account. Options: info,
            unknown, low, medium, high, criticial. Defaults to high,critical.
            ''',
            required=False,
            default='high,critical')
    parser.add_argument('--status',
            help='''
            Comma separated list of vulnerability statuses to take into account. Options: detected,
            confirmed, dismissed, resolved. Defaults to detected,confirmed.
            ''',
            default='detected,confirmed',
            required=False)
    parser.add_argument('--cachedir',
            help='Which directory to use for storing cached content (default: .cache)',
            default='.cache',
            required=False)
    parser.add_argument('--verbose',
            help='Show verbose output',
            action="store_true")
    args = parser.parse_args()


    # our arguments
    api = args.api
    diff = args.diff
    warn = args.warn
    crit = args.crit


    cachedir = args.cachedir
    verbose = args.verbose

    headers = { 'PRIVATE-TOKEN': args.token }
    # Split these into lists
    severity = args.severity.split(',')
    status = args.status.split(',')

    # pprint(diff)

    # start with clean slate
    ok_msg = []
    warn_msg = []
    crit_msg = []

    # Prepare the request
    r = requests.post(api, headers=headers)
    r.raise_for_status()

    # Fetchthe download URI for the security report
    security_report_download_url = r.json()['_links']['download']

    download = requests_retry_session().get(security_report_download_url, headers=headers)
    download.raise_for_status()

    reader = csv.DictReader(download.text.splitlines())
    
    # Filter the results
    filtered = filter(lambda d:
            d['Severity'] in severity and d['Status'] in status,
            reader)

    # vuls is a list of found vulnerabilities (dicts).
    # By using a set comprehension we deduplicate the list.
    vuls = [dict(i) for i in {tuple(d.items()) for d in filtered}]

    # pprint(len(vuls))
    # pprint(vuls)

    # accepts a list of vulnerability dicts, and returns a string report.
    # def report_result (vuls=vuls, diff=False, warn=warn, crit=crit):
    #     found = len(vuls)
    #     return f'''
    #     Found {found} vulnerabilities
    #     '''

    # prepare data
    data = json.dumps(vuls, indent=4)
    
    found_items = len(vuls)
    
    # print(report_result(vuls))

    message = (
            "Found " + str(found_items) + " issues with " +
            "severity " + " or ".join(severity) +
            ", and " +  "status " + " or ".join(status)
            )

    # We are only interested in the difference with the previous report
    if diff:
        cache = {}
        cachefile = PurePath(cachedir, PurePath( __file__).name).with_suffix('.cache.json')
        
        # Check if a cache file exists
        if os.path.isfile(cachefile):
            with open(cachefile, "r") as c:
                cache = c.read()
                # pprint("Cache was: " + cache)
            if data != cache:
                print("There were changes detected...")
                
                old = json.loads(cache)
                new = vuls

                difference = [i for i in new if i not in old] + [j for j in old if j not in new]
                d2 = [dict(t) for t in {tuple(d.items()) for d in difference}]
                pprint(d2)
                if len(new) > len(old):
                    print(str(len(difference)) + " new issues found")
                # pprint(type(old))

                elif len(old) > len(new):
                    print(str(len(difference)) + " less issues found")
                else:
                    print("same amount of issues, but differnce found")

                pprint(difference)
                # print("Now there are " + str(len(new)) + " issues")
                # pprint(type(new))

                # print("There are " + str(len(difference)) + " changes")

                # Save the current output to disk for next time
                with open(cachefile, "w") as c:
                    c.write(data)
            else:
                found_items = 0
                ok_msg.append("No changes compared to previous check")
        else:
            # Save the current output to disk for next time
            with open(cachefile, "w") as c:
                c.write(data)
            nagios_exit("UNKNOWN: no cache file yet", 3)







    if found_items > crit:
        crit_msg.append(message)
    elif found_items > warn:
        warn_msg.append(message)
    else:
        ok_msg.append(message)

except Exception as e:
    nagios_exit("UNKNOWN: {0}.".format(e), 3)

# Exit with accumulated message(s)
if crit_msg:
    nagios_exit("CRITICAL: " + ' '.join(crit_msg + warn_msg), 2)
elif warn_msg:
    nagios_exit("WARNING: " + ' '.join(warn_msg), 1)
else:
    nagios_exit("OK: " + '\n'.join(ok_msg), 0)
