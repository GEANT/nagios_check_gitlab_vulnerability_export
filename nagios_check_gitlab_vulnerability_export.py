#!/usr/bin/env python3
import argparse
import sys
from pprint import pprint
import csv
import json

# pip install requests
import requests

# https://www.peterbe.com/plog/best-practice-with-retries-with-requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
def requests_retry_session(
    retries=3,
    backoff_factor=0.3,
    status_forcelist=(500, 502, 504, 404),
    session=None,
):
    session = session or requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session


# Debug
# import logging
# logging.basicConfig(level=logging.DEBUG)

def nagios_exit(message, code):
    print(message)
    sys.exit(code)

try:
    parser = argparse.ArgumentParser(description='Monitor the vulnerabilities in Gitlab generated reports')
    parser.add_argument('--api',
            help='''
            The API URL to use. See https://docs.gitlab.com/ee/api/vulnerability_exports.html
            for examples. This can use project, group, or instance level reports.
            Example: "https://gitlab.my.org/api/v4/groups/234/vulnerability_exports"
            ''',
            required=True)
    parser.add_argument('--token',
            help='Access token to use for authentication',
            required=True)
    parser.add_argument('--diff',
            help='''
            Instead of the absolute number of vulnerabilties in the report, use the difference compared to
            the previous report. This effectively means you just see the changes.
            A temporary file will be used to store the relevant report details for comparison between
            checks. See also the '--cachedir' option.
            ''',
            action="store_false")
    parser.add_argument('--warn', '-w',
            help='Number of found vulnerabilities that should result in a WARNING (default: 1))',
            required=False,
            type=int,
            default=1)
    parser.add_argument('--crit', '-c',
            help='Number of found vulnerabilities that should result in a CRITICAL (default: 3))',
            required=False,
            type=int,
            default=3)
    parser.add_argument('--severity',
            help='''
            Comma separated list of vulnerability severities to take into account. Options: info,
            unknown, low, medium, high, criticial. Defaults to high,critical.
            ''',
            required=False,
            default='high,critical')
    parser.add_argument('--status',
            help='''
            Comma separated list of vulnerability statuses to take into account. Options: detected,
            confirmed, dismissed, resolved. Defaults to detected,confirmed.
            ''',
            default='detected,confirmed',
            required=False)
    parser.add_argument('--cachedir',
            help='Which directory to use for storing cached content (default: .cache)',
            default='.cache',
            required=False)
    parser.add_argument('--verbose',
            help='Show verbose output',
            action="store_true")
    

    args = parser.parse_args()


    # start with clean slate
    ok_msg = []
    warn_msg = []
    crit_msg = []

    # our arguments
    api = args.api
    token = args.token
    diff=args.diff

    warn=args.warn
    crit=args.crit

    # Split these into lists
    severity=args.severity.split(',')
    status=args.status.split(',')

    cachedir=args.cachedir
    verbose=args.verbose


    headers = { 'PRIVATE-TOKEN': token }


    r = requests.post(api, headers=headers)
    r.raise_for_status()

    # pprint(r.json())

    download_url = r.json()['_links']['download']

    d = requests_retry_session().get(download_url, headers=headers)
    d.raise_for_status()
    
    csv_data = d.text

    # print(csv_data)

    reader = csv.DictReader(d.text.splitlines())
    
    # Filter the results
    filtered = filter(lambda d:
            d['Severity'] in severity and d['Status'] in status,
            reader)

    # FIXME len(filtered) fails?
    j = []
    for i in filtered:
        # pprint(i)
        j.append(i)

    found_items = len(j)

    message = (
            "Found " + str(found_items) + " issues with " +
            "severity " + " or ".join(severity) +
            ", and " +  "status " + " or ".join(status)
            )

    if found_items > crit:
        crit_msg.append(message)
    elif found_items > warn:
        warn_msg.append(message)
    else:
        ok_msg.append(message)
    
except Exception as e:
    nagios_exit("UNKNOWN: {0}.".format(e), 3)

# Exit with accumulated message(s)
if crit_msg:
    nagios_exit("CRITICAL: " + ' '.join(crit_msg + warn_msg), 2)
elif warn_msg:
    nagios_exit("WARNING: " + ' '.join(warn_msg), 1)
else:
    nagios_exit("OK: " + '\n'.join(ok_msg), 0)
